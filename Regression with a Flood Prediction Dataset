{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":73278,"databundleVersionId":8121328,"sourceType":"competition"}],"dockerImageVersionId":30698,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-02T03:04:25.142977Z","iopub.execute_input":"2024-05-02T03:04:25.143382Z","iopub.status.idle":"2024-05-02T03:04:25.147873Z","shell.execute_reply.started":"2024-05-02T03:04:25.143353Z","shell.execute_reply":"2024-05-02T03:04:25.146992Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"train_ds=pd.read_csv('/kaggle/input/playground-series-s4e5/train.csv')\ntest_ds=pd.read_csv('/kaggle/input/playground-series-s4e5/test.csv')\ntrain_ds.info(), test_ds.info()","metadata":{"execution":{"iopub.status.busy":"2024-05-02T03:04:25.149690Z","iopub.execute_input":"2024-05-02T03:04:25.151018Z","iopub.status.idle":"2024-05-02T03:04:27.376164Z","shell.execute_reply.started":"2024-05-02T03:04:25.150989Z","shell.execute_reply":"2024-05-02T03:04:27.375192Z"},"trusted":true},"execution_count":73,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1117957 entries, 0 to 1117956\nData columns (total 22 columns):\n #   Column                           Non-Null Count    Dtype  \n---  ------                           --------------    -----  \n 0   id                               1117957 non-null  int64  \n 1   MonsoonIntensity                 1117957 non-null  int64  \n 2   TopographyDrainage               1117957 non-null  int64  \n 3   RiverManagement                  1117957 non-null  int64  \n 4   Deforestation                    1117957 non-null  int64  \n 5   Urbanization                     1117957 non-null  int64  \n 6   ClimateChange                    1117957 non-null  int64  \n 7   DamsQuality                      1117957 non-null  int64  \n 8   Siltation                        1117957 non-null  int64  \n 9   AgriculturalPractices            1117957 non-null  int64  \n 10  Encroachments                    1117957 non-null  int64  \n 11  IneffectiveDisasterPreparedness  1117957 non-null  int64  \n 12  DrainageSystems                  1117957 non-null  int64  \n 13  CoastalVulnerability             1117957 non-null  int64  \n 14  Landslides                       1117957 non-null  int64  \n 15  Watersheds                       1117957 non-null  int64  \n 16  DeterioratingInfrastructure      1117957 non-null  int64  \n 17  PopulationScore                  1117957 non-null  int64  \n 18  WetlandLoss                      1117957 non-null  int64  \n 19  InadequatePlanning               1117957 non-null  int64  \n 20  PoliticalFactors                 1117957 non-null  int64  \n 21  FloodProbability                 1117957 non-null  float64\ndtypes: float64(1), int64(21)\nmemory usage: 187.6 MB\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 745305 entries, 0 to 745304\nData columns (total 21 columns):\n #   Column                           Non-Null Count   Dtype\n---  ------                           --------------   -----\n 0   id                               745305 non-null  int64\n 1   MonsoonIntensity                 745305 non-null  int64\n 2   TopographyDrainage               745305 non-null  int64\n 3   RiverManagement                  745305 non-null  int64\n 4   Deforestation                    745305 non-null  int64\n 5   Urbanization                     745305 non-null  int64\n 6   ClimateChange                    745305 non-null  int64\n 7   DamsQuality                      745305 non-null  int64\n 8   Siltation                        745305 non-null  int64\n 9   AgriculturalPractices            745305 non-null  int64\n 10  Encroachments                    745305 non-null  int64\n 11  IneffectiveDisasterPreparedness  745305 non-null  int64\n 12  DrainageSystems                  745305 non-null  int64\n 13  CoastalVulnerability             745305 non-null  int64\n 14  Landslides                       745305 non-null  int64\n 15  Watersheds                       745305 non-null  int64\n 16  DeterioratingInfrastructure      745305 non-null  int64\n 17  PopulationScore                  745305 non-null  int64\n 18  WetlandLoss                      745305 non-null  int64\n 19  InadequatePlanning               745305 non-null  int64\n 20  PoliticalFactors                 745305 non-null  int64\ndtypes: int64(21)\nmemory usage: 119.4 MB\n","output_type":"stream"},{"execution_count":73,"output_type":"execute_result","data":{"text/plain":"(None, None)"},"metadata":{}}]},{"cell_type":"code","source":"count = np.isinf(train_ds).values.sum() \ncount","metadata":{"execution":{"iopub.status.busy":"2024-05-02T03:04:27.377953Z","iopub.execute_input":"2024-05-02T03:04:27.378241Z","iopub.status.idle":"2024-05-02T03:04:27.408547Z","shell.execute_reply.started":"2024-05-02T03:04:27.378217Z","shell.execute_reply":"2024-05-02T03:04:27.407633Z"},"trusted":true},"execution_count":74,"outputs":[{"execution_count":74,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"train_ds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds[train_ds.columns[1:]].corr()['FloodProbability'][ : ]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds=train_ds.drop(['id'],axis=1)\ntest_ds=test_ds.drop(['id'],axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Memory  optimization","metadata":{}},{"cell_type":"code","source":"memory_usage=train_ds.memory_usage().sum()/1024**2\nprint(\"memory usage before optimization :{:.2f} MB\".format(memory_usage))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"memory_usage=test_ds.memory_usage().sum()/1024**2\nprint(\"memory usage before optimization :{:.2f} MB\".format(memory_usage))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def memory_optimization(data_frame):\n    memory_usage=data_frame.memory_usage().sum()/1024**2\n    cols=data_frame.columns\n    for col in cols:\n        column_type=data_frame[col].dtype\n        \n        if column_type !=object:\n            col_min=data_frame[col].min()\n            col_max=data_frame[col].max()\n            if str(column_type)[:3]=='int':\n                if col_min > np.iinfo(np.int8).min and col_max< np.iinfo(np.int8).max:\n                    data_frame[col]=data_frame[col].astype(np.int8)\n                elif col_min > np.iinfo(np.int16).min and col_max< np.iinfo(np.int16).max:\n                    data_frame[col]=data_frame[col].astype(np.int16)\n                elif col_min > np.iinfo(np.int32).min and col_max< np.iinfo(np.int32).max:\n                    data_frame[col]=data_frame[col].astype(np.int32)\n                elif col_min > np.iinfo(np.int64).min and col_max< np.iinfo(np.int64).max:\n                    data_frame[col]=data_frame[col].astype(np.int64)\n            else:\n                if col_min > np.finfo(np.float16).min and col_max< np.finfo(np.float16).max:\n                    data_frame[col]=data_frame[col].astype(np.float16)\n                elif col_min > np.finfo(np.float32).min and col_max< np.finfo(np.float32).max:\n                    data_frame[col]=data_frame[col].astype(np.float32)\n                else:\n                    data_frame[col]=data_frame[col].astype(np.float64)\n        else:\n            data_frame[col]=data_frame[col].astype('object')\n    mem_usage=data_frame.memory_usage().sum()/1024**2\n    print(\"memory usage after optimization is: {:.2f} MB\".format(mem_usage))\n    print(\"memory usage reduce by: {:.2f}%\".format(100*(memory_usage-mem_usage)/memory_usage))\n    \n    return data_frame","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train=memory_optimization(train_ds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test=memory_optimization(test_ds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target=train['FloodProbability']\ntrain=train.drop(['FloodProbability'],axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\nfrom catboost import CatBoostRegressor\nfrom sklearn.datasets import make_regression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(train, target, test_size=0.2, random_state=42)\nrf = RandomForestRegressor(n_estimators=100, random_state=42)\nada = AdaBoostRegressor(n_estimators=100, random_state=42)\ngb = GradientBoostingRegressor(n_estimators=100, random_state=42)\ncat = CatBoostRegressor(iterations=100, learning_rate=0.1, random_state=42, verbose=0)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf.fit(X_train, y_train)\nada.fit(X_train, y_train) \ngb.fit(X_train, y_train)\ncat.fit(X_train, y_train)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf_pred = rf.predict(X_test)\nada_pred = ada.predict(X_test)\ngb_pred = gb.predict(X_test)\ncat_pred = cat.predict(X_test)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf_pred,ada_pred,gb_pred,cat_pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf_mse = mean_squared_error(y_test, rf_pred)\nprint(\"rf Mean Squared Error:\", rf_mse)\n\nada_mse = mean_squared_error(y_test, ada_pred)\nprint(\"ada Mean Squared Error:\", ada_mse)\n\ngb_mse = mean_squared_error(y_test, gb_pred)\nprint(\"gb Mean Squared Error:\", gb_mse)\n\ncat_mse = mean_squared_error(y_test, cat_pred)\nprint(\"cat Mean Squared Error:\", cat_mse)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = cat.predict(test)\npredictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission=pd.read_csv('/kaggle/input/playground-series-s4e5/sample_submission.csv')\nsubmission=submission.drop(['FloodProbability'],axis=1)\nsubmission['FloodProbability']=pd.DataFrame(predictions)\nsubmission","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('Submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}